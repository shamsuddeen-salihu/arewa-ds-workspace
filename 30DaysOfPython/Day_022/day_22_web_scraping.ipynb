{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Exercises: Day 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Community': {'Student Body': '37,557', 'Living Alumni': '431,000+', 'Total Employees': '10,674', 'Faculty': '4,309', 'Nondegree Students': '1,337', 'Graduate & Professional Students': '18,476', 'Undergraduate Students': '17,744'}, 'Campus': {'Classrooms': '848', 'Buildings': '343', 'Laboratories': '1,481', 'Libraries': '13', 'Campus Area (acres)': '140'}, 'Academics': {'Study Abroad Programs': '80+', 'Average Class Size': '30', 'Faculty': '4,309', 'Student/Faculty Ratio': '11:1', 'Schools and Colleges': '17', 'Programs of Study': '300+'}, 'Grant & Contract Awards': {'Research Expenditures': '$554.0M', 'Sponsored Research Awards': '$645.6M', 'BMC Clinical Research Grants (FY22)': '$82M'}, 'Undergraduate Financial Aid & Scholarships': {'Average Total Need-Based Financial Aid': '$57,237', 'Average Need-Based Grant/Scholarship': '$53,029', 'Grants & Scholarships (need-based)': '$388.4M', 'Grants & Scholarships (non-need-based)': '$26.5M'}, 'Student Life': {'Community Service Hours': '130,000+', 'BU on Social': 'new accounts daily', 'Cultural & Religious Organizations': '80+', 'Community Service & Justice Organizations': '70+', 'Academic & Professional Organizations': '140+', 'Art & Performance Organizations': '60+', 'Student Organizations': '450+', 'First-Year Student Outreach Project Volunteers': '400+'}, 'Research': {'Faculty Publications': '7,000+', 'Student UROP Participants': '475+', 'Centers & Institutes': '130+'}, 'International Community': {'Global Initiatives': '300+', 'Cultural Student Groups': '60+', 'Alumni Countries': '180+', 'International Students': '10,000+'}, 'Athletics': {'Intramural Sports & Tournaments': '12+', 'Club Sports': '36', 'Varsity Sports': '24'}}\n",
      "Bu Json file saved successfully\n"
     ]
    }
   ],
   "source": [
    "#Scrape the following website and store the data as json file(url = 'http://www.bu.edu/president/boston-university-facts-stats/').\n",
    "import requests, json\n",
    "from bs4 import BeautifulSoup\n",
    "url='http://www.bu.edu/president/boston-university-facts-stats/'\n",
    "response=requests.get(url)\n",
    "soup=BeautifulSoup(response.text, 'html.parser')\n",
    "#extract data\n",
    "facts_stats={}\n",
    "sections = soup.find_all('div', class_='facts-wrapper')\n",
    "for section in sections:\n",
    "    heading = section.find('h5').text.strip()\n",
    "    items = {item.find('p').text.strip(): item.find('span').text.strip() for item in section.find_all('li')}\n",
    "    facts_stats[heading] = items\n",
    "#save to json\n",
    "with open('bu_facts_stats.json', 'w', encoding='utf-8') as bu_file:\n",
    "    json.dump(facts_stats, bu_file, ensure_ascii=False, indent=4)\n",
    "print(facts_stats)\n",
    "print('Bu Json file saved successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been extracted and saved to uci_datasets.json\n"
     ]
    }
   ],
   "source": [
    "#Extract the table in this url (https://archive.ics.uci.edu/ml/datasets.php) and change it to a json file\n",
    "#url='https://archive.ics.uci.edu/ml/datasets.php'\n",
    "url='https://archive.ics.uci.edu/datasets'\n",
    "response=requests.get(url)\n",
    "soup=BeautifulSoup(response.text, 'html.parser')\n",
    "# Find the table on the webpage\n",
    "tables = soup.find_all('div', class_= 'rounded-box bg-base-100')\n",
    "\n",
    "# Extract table rows\n",
    "rows = []\n",
    "for table in tables:\n",
    "    name = table.find('a', class_='link-hover link text-xl font-semibold').text\n",
    "    des=table.find('p', class_='truncate').text.replace('\\n', '')\n",
    "    other_info=table.find_all('span', class_='truncate')\n",
    "    info_ls=[info.text for info in other_info]\n",
    "\n",
    "    row_dict={\n",
    "        'Dataset name': name,\n",
    "        'Dataset Description' : des,\n",
    "        'Task': info_ls[0],\n",
    "        'Data Type': info_ls[1],\n",
    "        'Instances': info_ls[2],\n",
    "        'Features': info_ls[3],   \n",
    "    }\n",
    "    rows.append(row_dict)\n",
    "\n",
    "# Save the data to a JSON file\n",
    "\n",
    "with open('uci_datasets.json', 'w', encoding='utf-8') as uci_file:\n",
    "    json.dump(rows, uci_file, ensure_ascii=False, indent=4)\n",
    "    #json_file.write(json_data)\n",
    "\n",
    "print('Dataset has been extracted and saved to uci_datasets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table has been extracted and saved to presidents_data.json\n"
     ]
    }
   ],
   "source": [
    "#Scrape the presidents table and store the data as json(https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States). The table is not very structured and the scrapping may take very long time.\n",
    "import re\n",
    "url='https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'\n",
    "response=requests.get(url)\n",
    "soup=BeautifulSoup(response.text, 'html.parser')\n",
    "#extract table\n",
    "table=soup.find('table', class_=\"wikitable sortable\")\n",
    "\n",
    "#extract rows\n",
    "rows=[]\n",
    "for row in table.find_all('tr')[1:]:\n",
    "    row_data = [re.sub(r'\\n|\\[[a-zA-Z0-9]+\\]', ' ',td.text.strip()) for td in row.find_all('td')]\n",
    "    s_num = row.find('th').text.replace('\\n', '')\n",
    "    \n",
    "    row_dict={\n",
    "        \"No.\": s_num,\n",
    "        \"Portrait\": row_data[0],\n",
    "        \"Name(Birthâ€“Death)\": row_data[1],\n",
    "        \"Term\": row_data[2],\n",
    "        \"Party\": row_data[4],\n",
    "        \"Election\": row_data[5],\n",
    "        \"Vice President\": row_data[6]\n",
    "     }\n",
    "    rows.append(row_dict)\n",
    "\n",
    "#save the file as json\n",
    "with open('presidents_data.json', 'w', encoding='utf-8') as president_file:\n",
    "    json.dump(rows, president_file, ensure_ascii=False, indent=4)\n",
    "    #json_file.write(json_data)\n",
    "\n",
    "print('Table has been extracted and saved to presidents_data.json')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
